{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqGJpQTYpDaM"
      },
      "source": [
        "# Testing a Black Box: Detecting Bias in a Medical Risk Score Algorithm\n",
        "---\n",
        "\n",
        "ML Failures lab: Dissecting Racial Bias in a Medical Risk Score by Nick Merrill, Inderpal Kaur, Samuel Greenberg is licensed under [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0).\n",
        "\n",
        "This lab is based off of [Dissecting racial bias in an algorithm used to manage the health of populations](https://science.sciencemag.org/content/366/6464/447) by Ziad Obermeyer et al (2019).\n",
        "\n",
        "\n",
        "# Background\n",
        "\n",
        "To effectively manage patients, health systems often need to estimate patients' health risks. By calculating numerical \"risk scores\" for patients, healthcare providers can prioritize patients who are most at-risk and allocate more resources to them.\n",
        "\n",
        "In this lab, we examine an algorithm widely-used in industry to assign medical risk scores to patients. For each patient, the algorithm uses *medical cost* (i.e., the amount a patient spends on medical care) to calculate their **risk score**. Some other features the model also takes in include details about the patient's medical history.\n",
        "\n",
        "We've received some reports of concerns about racial bias in AI risk scoring systems, so want to test the AI to check for bias. However, we can't see the algorithm or data because this is a proprietary model trained on private medical information. What we can do is send inputs (hypothetical patient data) to the model and see the corresponding outputs (the hypothetical patient's risk score).\n",
        "\n",
        "Let's see what we can uncover about this black box model just by **testing various inputs**!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kchmUYpczGn_",
        "cellView": "form"
      },
      "source": [
        "#@title Preparation: click the play button to load the input data we use to test the AI.\n",
        "\n",
        "%%capture\n",
        "# import statements\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.ticker\n",
        "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
        "%matplotlib inline\n",
        "\n",
        "#utility function\n",
        "def convert_to_percentile(df, col_name):\n",
        "    \"\"\"\n",
        "    Convert df column col_name to percentile.\n",
        "    \"\"\"\n",
        "    return pd.qcut(df[col_name].rank(method='first'), 100, labels=range(1, 101))\n",
        "\n",
        "# first, let's load the data we will need\n",
        "# download this data at \n",
        "# https://github.com/daylight-lab/mlfailures/blob/master/health-care-bias-lab.csv\n",
        "!wget https://raw.githubusercontent.com/daylight-lab/mlfailures/master/health-care-bias-lab.csv\n",
        "data = pd.read_csv('health-care-bias-lab.csv')\n",
        "\n",
        "#add a column of risk percentiles to the dataframe called 'risk_percentile'\n",
        "risk_percentile = convert_to_percentile(data, \"risk_score_t\")\n",
        "data[\"risk_percentile\"] = risk_percentile\n",
        "data[\"race\"] = data[\"race\"].str.replace(\"black\", \"Black\").replace(\"white\", \"White\")\n",
        "\n",
        "data_subset = data[[\"risk_percentile\", \"race\", \"cost_t\", \"gagne_sum_t\"]].rename({\"risk_percentile\": \"Risk Score\", \n",
        "                                                                                 \"race\": \"Race\", \"cost_t\": \"Medical Cost\", \n",
        "                                                                                 \"gagne_sum_t\": \"Illness\"}, axis=1)\n",
        "inputs = data_subset[[\"Race\", \"Medical Cost\", \"Illness\"]]\n",
        "outputs = data_subset[[\"Risk Score\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Preview: click the play button to view the data in detail.\n",
        "\n",
        "print(\"The inputs we sent to the model...\", \"\\n\")\n",
        "print(inputs.head(), \"\\n\")\n",
        "print(\"The risk score outputs we got back from the model...\", \"\\n\")\n",
        "print(outputs.head())"
      ],
      "metadata": {
        "id": "TyhVxVPoDQeG",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY-sa4O5IqCJ"
      },
      "source": [
        "## Medical Cost and Risk Score\n",
        "\n",
        "Since the AI is using medical cost to calculate the risk scores, we expect patients with higher medical costs to have higher risk scores. If our algorithm is fair, the relationship between a patient's input cost and their output risk score shouldn't change based on the patient's race. In other words, patients with the same cost should have similar risk scores regardless of their race.\n",
        "\n",
        "To check this relationship, we can show the input cost and the output risk on a chart like the one below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6PlT59kLq_F",
        "collapsed": true
      },
      "source": [
        "#@title Click play to display a chart of the relationship between cost and risk score.\n",
        "\n",
        "# fit a LOWESS (Locally Weighted Scatterplot Smoothing) model to the scatterplot above for each race\n",
        "def LowessForScoreToCost(data):\n",
        "  return lowess(np.array(data['Medical Cost']), np.array(data['Risk Score']), it=35, frac=0.2, delta=2)[:, 1]\n",
        "\n",
        "\n",
        "#create dataframe with the average total medical expenditure for each race at each risk percentile\n",
        "group_cost = data_subset.groupby([\"Risk Score\", \"Race\"])[[\"Medical Cost\"]].mean().reset_index()\n",
        "\n",
        "#divide group_cost into two dataframes based on race\n",
        "group_cost_black = group_cost[group_cost['Race'] == 'Black']\n",
        "group_cost_white = group_cost[group_cost['Race'] == 'White']\n",
        "\n",
        "# Calculate the curve for group \"black\" by LOWESS \n",
        "lowess_black = LowessForScoreToCost(group_cost_black)\n",
        "\n",
        "## TODO：Please change this line of code to make the result correct!\n",
        "## \"correct\" means you can see another curve in orange showing in the chart generated below.\n",
        "lowess_white = np.zeros(len(group_cost_white))\n",
        "\n",
        "\n",
        "# Plot the scatter chart\n",
        "plt.figure(figsize=(12,7))\n",
        "ax = sns.scatterplot(x = \"Risk Score\", y = \"Medical Cost\", data = group_cost, hue = \"Race\", marker = \"x\")\n",
        "plt.yscale('log')\n",
        "plt.plot(group_cost_black['Risk Score'], lowess_black)\n",
        "plt.plot(group_cost_white['Risk Score'], lowess_white)\n",
        "ax.set_yticks([1000, 3000, 8000, 20000, 60000])\n",
        "ax.get_yaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EHyhQ6HJXbf"
      },
      "source": [
        "**QUESTIONS:**\n",
        "1. If you were to pick a Black patient and a white patient from this dataset, both with identical medical costs, would you expect the algorithm to systematically assign a higher risk score to one or the other?\n",
        "2. Can you conclude from this data alone that the model is fair or not fair?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19CQRP0cJvU5"
      },
      "source": [
        "## Chronic Illness and Risk Score\n",
        "\n",
        "The purpose of the risk score is to identify patients who will likely need high-risk care or have more illnesses that require medical attention. This means that patients with more illnesses should have higher risk scores.\n",
        "\n",
        "Again, we want to make sure that patients with the same level of illness get the same risk scores regardless of race. Let's make another plot like the one above to show these relationships.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il7plqyK5ha5"
      },
      "source": [
        "#@title Click play to display a chart of the relationship between number of chronic illnesses and risk score...\n",
        "\n",
        "# Fit a Generalized Linear Model (GLM) to the scatterplot above for each race\n",
        "def Glm(data):\n",
        "  X_b = sm.add_constant(np.array(data[\"Risk Score\"]))\n",
        "  glm = sm.GLM(data[\"Illness\"], X_b, family=sm.families.Gaussian(link=sm.families.links.log())).fit()\n",
        "  return glm.predict()\n",
        "\n",
        "\n",
        "# Create dataframe with the average number of chronic illnesses for each race at each risk percentile\n",
        "group_illness = data_subset.groupby([\"Risk Score\", \"Race\"])[[\"Illness\"]].mean().reset_index()\n",
        "\n",
        "# Divide the grouped dataframe into two dataframes based on race\n",
        "group_illness_black = group_illness[group_illness['Race'] == 'Black']\n",
        "group_illness_white = group_illness[group_illness['Race'] == 'White']\n",
        "\n",
        "# Calculate the curve for group \"white\" by GLM\n",
        "illness_white = Glm(group_illness_white)\n",
        "\n",
        "## TODO：Please change this line of code to make the result correct!\n",
        "## \"correct\" means you can see the blue line becomes a curve along with those blue data points in the chart.\n",
        "illness_black = np.zeros(len(group_illness_black))\n",
        "\n",
        "# Plot the model on the scatter chart\n",
        "plt.figure(figsize=(12,7))\n",
        "sns.scatterplot(x=\"Risk Score\", y=\"Illness\", data=group_illness, hue=\"Race\", marker=\"x\")\n",
        "plt.plot(group_illness_black[\"Risk Score\"], illness_black)\n",
        "plt.plot(group_illness_white[\"Risk Score\"], illness_white)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIEeHKYUKb-j"
      },
      "source": [
        "**QUESTIONS:**\n",
        "1. If you were to pick a Black patient and a white patient from this dataset, both with identical number of chronic illnesses, would you expect the algorithm to systematically assign a higher risk score to one or the other?\n",
        "2. Can you conclude from this data alone that the model is fair or not fair?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZhqmFQOKuxi"
      },
      "source": [
        "## What Went Wrong?\n",
        "\n",
        "The charts above show us that a Black patient and a White patient who have the same medical cost will get similar risk scores from the AI system. However, a Black patient and a White patient who have the same number of illnesses can get very different risk scores. Specifically, the Black patient will be predicted to have a lower risk score than the white patient. \n",
        "\n",
        "Imagine: a Black patient and a white patient walk into the same hospital at the same time. Their medical records are identical. The algorithm would recommend that the white patient be triaged before the Black patient! \n",
        "\n",
        "How did this happen? \n",
        "\n",
        "To get to the bottom of this effect, let's look at the relationship between medical cost and number of illness, by race."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OootdJVKLyCx"
      },
      "source": [
        "#@title Click play to display a chart of the relationship between number of chronic illnesses and medical cost...\n",
        "\n",
        "#fit a LOWESS (Locally Weighted Scatterplot Smoothing) model to the scatterplot above for each race\n",
        "def LowessForCostToIllness(data):\n",
        "  return lowess(np.array(data['Medical Cost']), np.array(data['Illness (%-tile)']), it=35, frac=0.3, delta=2)[:, 1]\n",
        "\n",
        "#add a column of illness percentiles to the dataframe called 'illness_percentile'\n",
        "illness_percentile = convert_to_percentile(data_subset, \"Illness\")\n",
        "data_subset['Illness (%-tile)'] = illness_percentile\n",
        "#create dataframe with the average total medical expenditure for each race at each illness percentile\n",
        "illnesses = data_subset.groupby(['Illness (%-tile)', \"Race\"])[[\"Medical Cost\"]].mean().reset_index()\n",
        "\n",
        "#divide illnesses into two dataframes based on race\n",
        "illness_b = illnesses[illnesses['Race'] == 'Black']\n",
        "illness_w = illnesses[illnesses['Race'] == 'White']\n",
        "\n",
        "\n",
        "# Calculate the curve for group \"white\" by LOWESS\n",
        "white_lowessC2I = LowessForCostToIllness(illness_w)\n",
        "\n",
        "## TODO：Please change this line of code to make the result correct!\n",
        "## \"correct\" means you can see another curve in orange showing in the chart generated below.\n",
        "black_lowessC2I = np.zeros(len(illness_b))\n",
        "\n",
        "\n",
        "# Plot the model on the scatter chart\n",
        "plt.figure(figsize=(12,7))\n",
        "ax = sns.scatterplot(x = \"Illness (%-tile)\", y = \"Medical Cost\", data = illnesses, hue = \"Race\", marker = \"x\")\n",
        "plt.plot(illness_b[\"Illness (%-tile)\"], black_lowessC2I)\n",
        "plt.plot(illness_w[\"Illness (%-tile)\"], white_lowessC2I)\n",
        "plt.yscale('log')\n",
        "ax.set_yticks([1000, 3000, 8000, 20000, 60000])\n",
        "ax.get_yaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWVBYMvMNRei"
      },
      "source": [
        "**Questions:**\n",
        "1. If you were to pick a Black patient and a white patient from this dataset, both with an identical number of chronic illnesses, would you expect either patient to systematically spend more on their health care costs?\n",
        "2. How did this discrepancy caused the algorithm to underestimate the medical risk to Black patients?\n",
        "3. Why might we observe this discrepancy?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esq4RAPfOnro"
      },
      "source": [
        "\n",
        "## Conclusions and takeaways\n",
        "\n",
        "The AI system used to calculate patient risk scores might be a black box, but we were still able to find evidence of bias in the model by testing it with different inputs and displaying the relationship with the output.\n",
        "\n",
        "The takeaway here is clear: we can identify bias in black-box models---*as long as we have access to the sensitive features.*\n",
        "\n",
        "When we drilled down into this bias, we discovered a cause: given a Black patient and a white patient with the same number of chronic illnesses, the white patient will spend more on their health care. But why? Obermeyer et al. opined in the Nature paper on which this lab is based:\n",
        " \n",
        ">The literature broadly suggests two main potential channels. First, poor patients face substantial barriers to accessing health care, even when enrolled in insurance plans. Although the population we study is entirely insured, there are many other mechanisms by which poverty can lead to disparities in use of health care: geography and differential access to transportation, competing demands from jobs or child care, or knowledge of reasons to seek care (1-3). To the extent that race and socioeconomic status are correlated, these factors will differentially affect Black patients. Second, race could affect costs directly via several channels: direct (“taste-based”) discrimination, changes to the doctor–patient relationship, or others. A recent trial randomly assigned Black patients to a Black or White primary care provider and found significantly higher uptake of recommended preventive care when the provider was Black (4). This is perhaps the most rigorous demonstration of this effect, and it fits with a larger literature on potential mechanisms by which race can affect health care directly. For example, it has long been documented that Black patients have reduced trust in the health care system (5), a fact that some studies trace to the revelations of the Tuskegee study and other adverse experiences (6). A substantial literature in psychology has documented physicians’ differential perceptions of Black patients, in terms of intelligence, affiliation (7), or pain tolerance (8). **Thus, whether it is communication, trust, or bias, something about the interactions of Black patients with the health care system itself leads to reduced use of health care. The collective effect of these many channels is to lower health spending substantially for Black patients, conditional on need—a finding that has been appreciated for at least two decades (9).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZckgMXS24TYX"
      },
      "source": [
        "## Reflection Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeHiQ6fz3nuC"
      },
      "source": [
        "Here is a final open-ended question for you to answer.\n",
        "\n",
        "1. How could we use the data we have to create new proxies for health needs that may be less biased than medical costs?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpnQ5tGH4A-9"
      },
      "source": [
        "## References\n",
        "\n",
        "1. K. Fiscella, P. Franks, M. R. Gold, C. M. Clancy, JAMA 283, 2579–2584 (2000).\n",
        "2. N. E. Adler, K. Newman, Health Aff. 21, 60–76 (2002).\n",
        "3. N. E. Adler, W. T. Boyce, M. A. Chesney, S. Folkman, S. L. Syme, JAMA 269, 3140–3145 (1993).\n",
        "4. M. Alsan, O. Garrick, G. C. Graziani, “Does diversity matter for health? Experimental evidence from Oakland” (National Bureau of Economic Research, 2018).\n",
        "5. K. Armstrong, K. L. Ravenell, S. McMurphy, M. Putt, Am. J. Public Health 97, 1283–1289 (2007).\n",
        "6. M. Alsan, M. Wanamaker, Q. J. Econ. 133, 407–455 (2018).\n",
        "7. M. van Ryn, J. Burke, Soc. Sci. Med. 50, 813–828 (2000).\n",
        "8. K. M. Hoffman, S. Trawalter, J. R. Axt, M. N. Oliver, Proc. Natl. Acad. Sci. U.S.A. 113, 4296–4301 (2016).\n",
        "9. J. J. Escarce, F. W. Puffer, in Racial and Ethnic Differences in the Health of Older Americans (National Academies Press, 1997), chap. 6; www.ncbi.nlm.nih.gov/books/ NBK109841/.\n",
        "\n",
        "<!-- # Feedback\n",
        "\n",
        "**Instructors**: Please [provide feedback](https://docs.google.com/forms/d/1UuUVBBMTU_2aMvzsGnTR_4i1w3F6tLaaqdIr7dQrgSI/edit?ts=5efa771b&dods) to help improve this lab.\n",
        "\n",
        "**Students**: Please [provide feedback](https://docs.google.com/forms/d/1jI8oXRkqD1l1ARuZR1y9W_qkOystPr-YEyywNDez46M/edit?ts=5efa772a&dods) to help improve this lab. -->\n"
      ]
    }
  ]
}